{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ğŸ” Omni-Scanner Pro v2 â€” å…¨å¸‚å ´å½¢æ…‹æƒæç³»çµ±\n\n| åŠŸèƒ½ | èªªæ˜ |\n|------|------|\n| å°è‚¡æ•¸æ“š | FinMind REST API (å…¨ä¸Šå¸‚ + ä¸Šæ«ƒ ~3,600 æª”) |\n| ç¾è‚¡æ•¸æ“š | Tiingo REST API (å…¨ NYSE + NASDAQ ~7,000+ æ´»èºè‚¡) |\n| å¿«å– | 12 å°æ™‚æª”æ¡ˆå¿«å– (é¦–æ¬¡æƒæå¾Œå¤§å¹…åŠ é€Ÿ) |\n| è©•åˆ† | å¹¾ä½• 50% + é‡èƒ½ 20% + OB 15% + Fibo 15% |\n| é–€æª» | åªé¡¯ç¤º â‰¥ 75 åˆ† |\n| æƒææ¨¡å¼ | âš¡ å¿«é€Ÿ (~120 æª”) / ğŸŒ å…¨å¸‚å ´ (å…¨ä¸Šå¸‚å…¬å¸) |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ğŸ“¦ Step 1: å®‰è£å¥—ä»¶ (ä¸å‹• Colab é è£ç’°å¢ƒ)\n\n# âš ï¸ é—œéµï¼šä¸å¸è¼‰ã€ä¸å‡ç´š numpy / scipy / pandas\n# Colab é è£ç‰ˆæœ¬å·²ç¶“å¤ ç”¨ï¼Œå‹•å®ƒå€‘æœƒé€ æˆé€£é–è¡çª\n# requests / numpy / pandas / scipy / ipywidgets å‡ç‚º Colab é è£\n!pip install plotly tqdm yfinance --quiet 2>/dev/null\n\nprint('âœ… å®‰è£å®Œæˆ')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ğŸ“¥ Step 2: ç’°å¢ƒæª¢æŸ¥\n\nimport importlib, sys\n\ndef check(name):\n    try:\n        m = importlib.import_module(name)\n        v = getattr(m, '__version__', '?')\n        print(f'  âœ… {name} ({v})')\n        return True\n    except ImportError:\n        print(f'  âŒ {name}')\n        return False\n\nprint('ğŸ“‹ ç’°å¢ƒæª¢æŸ¥:')\nprint(f'  Python {sys.version.split()[0]}')\ncheck('numpy')\ncheck('pandas')\ncheck('scipy')\ncheck('plotly')\ncheck('requests')\ncheck('tqdm')\ncheck('ipywidgets')\ncheck('yfinance')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title âš™ï¸ Step 3: æ™ºæ…§å‹ K ç·šå½¢æ…‹è¾¨è­˜å¼•æ“ (é åˆ¤å‹)\n\n# ============================================================\n# å¥—ä»¶åŒ¯å…¥\n# ============================================================\n\nimport os, sys, time, json, warnings, io, zipfile, csv, math\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass, field\nfrom typing import List, Dict, Optional, Tuple\n\nimport requests as _requests\nimport numpy as np\nimport pandas as pd\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.io as pio\n\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output, HTML\n\nfrom tqdm.auto import tqdm\n\nwarnings.filterwarnings('ignore')\n\n# yfinance å‚™æ´\ntry:\n    import yfinance as yf\n    _HAS_YF = True\nexcept ImportError:\n    _HAS_YF = False\n\n# Colab ç’°å¢ƒåµæ¸¬\ntry:\n    import google.colab\n    _IN_COLAB = True\n    pio.renderers.default = 'colab'\nexcept ImportError:\n    _IN_COLAB = False\n\n# pandas ç‰ˆæœ¬æª¢æŸ¥\n_PD_VER = tuple(int(x) for x in pd.__version__.split('.')[:2])\n_MONTH_RULE = 'ME' if _PD_VER >= (2, 1) else 'M'\n\n# ============================================================\n# å…¨åŸŸè¨­å®š (ä¾è¦æ ¼æ›¸)\n# ============================================================\n\nCACHE_DIR = Path('./cache')\nCACHE_DIR.mkdir(parents=True, exist_ok=True)\n\nCACHE_EXPIRY_HOURS = 12\n\n# ZigZag åƒæ•¸ (è¦æ ¼æ›¸ 2.2)\nZIGZAG_THRESHOLD = 0.03    # 3% å›èª¿é–€æª»\nZIGZAG_MIN_BARS = 3        # æœ€å°è·¨åº¦\n\n# å½¢æ…‹åƒæ•¸ (è¦æ ¼æ›¸ 3.x)\nTOLERANCE = 0.03           # èª¤å·®å®¹å¿åº¦ 3%\nNECKLINE_MIN_HEIGHT = 0.08 # Wåº•/Mé ­é ¸ç·šæœ€å°é«˜åº¦ 8%\nMIN_PATTERN_BARS = 15      # å½¢æ…‹æœ€å°è·¨åº¦\nHS_SYMMETRY_TOL = 0.10     # é ­è‚©å°ç¨±å®¹å·® 10%\nNECKLINE_MAX_SLOPE = 30    # é ¸ç·šæœ€å¤§æ–œç‡åº¦æ•¸\n\n# é åˆ¤è§¸ç™¼åƒæ•¸ (è¦æ ¼æ›¸ 4.x)\nTRIGGER_THRESHOLD = 0.02   # 2% åå½ˆ/å›è½è§¸ç™¼\n\n# è©•åˆ†åƒæ•¸ (è¦æ ¼æ›¸ 5.x)\nQUALITY_THRESHOLD = 65     # å“è³ªåˆ†æ•¸é–€æª»\nWEIGHT_VOLUME = 0.40       # æˆäº¤é‡æ¬Šé‡ 40%\nWEIGHT_TREND = 0.30        # è¶¨å‹¢ä½ç½®æ¬Šé‡ 30%\nWEIGHT_MORPHOLOGY = 0.30   # å½¢æ…‹å®Œæ•´åº¦æ¬Šé‡ 30%\n\n# æ™‚æ¡†è¨­å®š\nTIMEFRAMES = ['1M', '1W', '1D']\nTF_LABELS = {'1D': 'æ—¥ç·š', '1W': 'é€±ç·š', '1M': 'æœˆç·š'}\n\n# API é€Ÿç‡æ§åˆ¶\nTIINGO_RATE_DELAY = 1.5\nFINMIND_RATE_DELAY = 0.35\n\n# ç²¾é¸æ¸…å–®\nQUICK_LIST = {\n    'TW': [\n        '2330','2454','2317','2382','2303','3711','2379','3034',\n        '6770','2408','3231','2354','2395','3008','2474','6505',\n        '2881','2882','2884','2886','2891','2892','5880','2885',\n        '1301','1303','1326','2603','2609','2615','2002','1402',\n        '6446','4904','3045','2912','9910','2207','1216','2105',\n    ],\n    'US': [\n        'AAPL','MSFT','GOOGL','AMZN','META','NVDA','TSLA','NFLX',\n        'AMD','INTC','AVGO','QCOM','MU','MRVL','AMAT','LRCX',\n        'KLAC','ON','TXN','ADI','CRM','ORCL','ADBE','NOW',\n        'SNOW','PLTR','PANW','CRWD','DDOG','NET','ZS','MNDY',\n        'SHOP','PINS','SNAP','ROKU','PYPL','COIN','UBER',\n        'LLY','UNH','JNJ','ABBV','MRK','PFE','TMO','ISRG',\n        'JPM','BAC','GS','MS','V','MA','AXP','BLK',\n        'XOM','CVX','COP','SLB','FCX','NEM',\n        'WMT','COST','HD','NKE','SBUX','MCD','DIS','ABNB',\n        'SPY','QQQ','IWM','XLF','XLE','XLK','SOXX','ARKK',\n    ],\n}\n\n# ============================================================\n# æ•¸æ“šçµæ§‹ (è¦æ ¼æ›¸ 6)\n# ============================================================\n\n@dataclass\nclass Pivot:\n    \"\"\"ZigZag è½‰æŠ˜é»\"\"\"\n    idx: int           # Kç·šç´¢å¼•\n    price: float       # åƒ¹æ ¼\n    type: str          # 'PEAK' æˆ– 'VALLEY'\n    date: str          # æ—¥æœŸå­—ä¸²\n\n@dataclass\nclass Pattern:\n    \"\"\"è­˜åˆ¥åˆ°çš„å½¢æ…‹\"\"\"\n    type: str          # DOUBLE_BOTTOM, DOUBLE_TOP, HS_BOTTOM, HS_TOP, CUP_HANDLE\n    direction: str     # bullish æˆ– bearish\n    pivots: List[Pivot]\n    neckline: float\n    end_idx: int\n\n@dataclass\nclass PatternSignal:\n    \"\"\"è¼¸å‡ºè¨Šè™Ÿ (è¦æ ¼æ›¸ 6)\"\"\"\n    symbol: str\n    pattern_type: str\n    signal_type: str   # PREDICTIVE_LONG æˆ– PREDICTIVE_SHORT\n    timestamp: str\n    timeframe: str\n    quality_score: int\n    entry_zone: float\n    stop_loss: float\n    target_neckline: float\n    measured_move_target: float\n    risk_reward_ratio: float\n    pattern_details: Dict = field(default_factory=dict)\n    score_breakdown: Dict = field(default_factory=dict)\n\n# ============================================================\n# æƒææ§åˆ¶\n# ============================================================\n\nclass ScanControl:\n    def __init__(self):\n        self.stop_flag = False\n    def stop(self):\n        self.stop_flag = True\n    def reset(self):\n        self.stop_flag = False\n    @property\n    def should_stop(self):\n        return self.stop_flag\n\nscan_ctrl = ScanControl()\n\n# ============================================================\n# Ticker Registry\n# ============================================================\n\nclass TickerRegistry:\n    _cache_file = CACHE_DIR / '_ticker_registry.json'\n\n    @staticmethod\n    def _load():\n        try:\n            return json.loads(TickerRegistry._cache_file.read_text())\n        except Exception:\n            return {}\n\n    @staticmethod\n    def _save(d):\n        TickerRegistry._cache_file.write_text(json.dumps(d, ensure_ascii=False))\n\n    @staticmethod\n    def fetch_us(tiingo_key: str) -> List[str]:\n        cache = TickerRegistry._load()\n        if cache.get('US') and cache.get('US_ts'):\n            try:\n                age = (datetime.now() - datetime.fromisoformat(cache['US_ts'])).total_seconds()\n                if age < 86400:\n                    return cache['US']\n            except Exception:\n                pass\n\n        url = 'https://apimedia.tiingo.com/docs/tiingo/daily/supported_tickers.zip'\n        r = _requests.get(url, timeout=60)\n        if r.status_code != 200:\n            raise RuntimeError(f'Tiingo æ¸…å–®ä¸‹è¼‰å¤±æ•—: HTTP {r.status_code}')\n\n        z = zipfile.ZipFile(io.BytesIO(r.content))\n        with z.open(z.namelist()[0]) as f:\n            rows = list(csv.DictReader(io.TextIOWrapper(f)))\n\n        cutoff = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n        tickers = sorted(set(\n            row['ticker'] for row in rows\n            if row.get('exchange') in ('NYSE', 'NASDAQ')\n            and row.get('assetType') == 'Stock'\n            and row.get('endDate', '') >= cutoff\n        ))\n\n        cache['US'] = tickers\n        cache['US_ts'] = datetime.now().isoformat()\n        TickerRegistry._save(cache)\n        return tickers\n\n    @staticmethod\n    def fetch_tw(finmind_token: str = '') -> List[str]:\n        cache = TickerRegistry._load()\n        if cache.get('TW') and cache.get('TW_ts'):\n            try:\n                age = (datetime.now() - datetime.fromisoformat(cache['TW_ts'])).total_seconds()\n                if age < 86400:\n                    return cache['TW']\n            except Exception:\n                pass\n\n        params = {'dataset': 'TaiwanStockInfo'}\n        if finmind_token:\n            params['token'] = finmind_token\n        r = _requests.get('https://api.finmindtrade.com/api/v4/data', params=params, timeout=30)\n        data = r.json()\n        if data.get('status') != 200:\n            raise RuntimeError(f'FinMind éŒ¯èª¤: {data.get(\"msg\")}')\n\n        tickers = sorted(set(\n            s['stock_id'] for s in data['data']\n            if s.get('type') in ('twse', 'tpex')\n        ))\n\n        cache['TW'] = tickers\n        cache['TW_ts'] = datetime.now().isoformat()\n        TickerRegistry._save(cache)\n        return tickers\n\n# ============================================================\n# DataManager (è³‡æ–™ç®¡ç†)\n# ============================================================\n\nclass DataManager:\n    def __init__(self, finmind_token='', tiingo_key=''):\n        self.fm_token = finmind_token\n        self.tg_key = tiingo_key\n        self.session = _requests.Session()\n        self._last_us = 0\n        self._last_tw = 0\n        self._backoff = 0\n        self.stats = {'api_us': 0, 'api_tw': 0, 'yf_fallback': 0, 'cache': 0, 'err': 0}\n\n    def _cache_path(self, ticker, market):\n        return CACHE_DIR / f\"{market}_{ticker.replace('.','_')}.csv\"\n\n    def _cache_ok(self, p):\n        if not p.exists():\n            return False\n        age = (datetime.now() - datetime.fromtimestamp(p.stat().st_mtime)).total_seconds()\n        return age < CACHE_EXPIRY_HOURS * 3600\n\n    def _wait_us(self):\n        delay = TIINGO_RATE_DELAY + self._backoff\n        gap = time.time() - self._last_us\n        if gap < delay:\n            time.sleep(delay - gap)\n        self._last_us = time.time()\n\n    def _wait_tw(self):\n        gap = time.time() - self._last_tw\n        if gap < FINMIND_RATE_DELAY:\n            time.sleep(FINMIND_RATE_DELAY - gap)\n        self._last_tw = time.time()\n\n    def _fetch_us(self, ticker):\n        self._wait_us()\n        end = datetime.now()\n        start = end - timedelta(days=2000)\n        url = f'https://api.tiingo.com/tiingo/daily/{ticker}/prices'\n        params = {\n            'startDate': start.strftime('%Y-%m-%d'),\n            'endDate': end.strftime('%Y-%m-%d'),\n            'token': self.tg_key\n        }\n        r = self.session.get(url, params=params, timeout=15)\n        if r.status_code == 429:\n            self._backoff = min(30, self._backoff + 3)\n            time.sleep(self._backoff)\n            self._last_us = time.time()\n            r = self.session.get(url, params=params, timeout=15)\n        if r.status_code != 200:\n            raise ValueError(f'Tiingo HTTP {r.status_code}')\n        data = r.json()\n        if not data:\n            raise ValueError('Tiingo ç„¡æ•¸æ“š')\n        df = pd.DataFrame(data)\n        df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)\n        df = df.set_index('date')\n        adj_cols = ['adjOpen', 'adjHigh', 'adjLow', 'adjClose', 'adjVolume']\n        df = df[adj_cols].copy()\n        df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n        self.stats['api_us'] += 1\n        self._backoff = max(0, self._backoff - 0.5)\n        return df\n\n    def _fetch_us_yf(self, ticker):\n        if not _HAS_YF:\n            raise ImportError('yfinance æœªå®‰è£')\n        end = datetime.now()\n        start = end - timedelta(days=2000)\n        df = yf.download(ticker, start=start.strftime('%Y-%m-%d'),\n                         end=end.strftime('%Y-%m-%d'), progress=False, auto_adjust=True)\n        if df is None or df.empty:\n            raise ValueError('yfinance ç„¡æ•¸æ“š')\n        if isinstance(df.columns, pd.MultiIndex):\n            df.columns = df.columns.get_level_values(0)\n        self.stats['yf_fallback'] += 1\n        return df\n\n    def _fetch_tw(self, ticker):\n        self._wait_tw()\n        end = datetime.now()\n        start = end - timedelta(days=2000)\n        params = {\n            'dataset': 'TaiwanStockPrice',\n            'data_id': ticker,\n            'start_date': start.strftime('%Y-%m-%d'),\n            'end_date': end.strftime('%Y-%m-%d'),\n        }\n        if self.fm_token:\n            params['token'] = self.fm_token\n        r = self.session.get('https://api.finmindtrade.com/api/v4/data', params=params, timeout=15)\n        data = r.json()\n        if data.get('status') != 200:\n            raise ValueError(f'FinMind: {data.get(\"msg\",\"\")}')\n        rows = data['data']\n        if not rows:\n            raise ValueError('FinMind ç„¡æ•¸æ“š')\n        df = pd.DataFrame(rows)\n        df['date'] = pd.to_datetime(df['date'])\n        df = df.set_index('date')\n        self.stats['api_tw'] += 1\n        return df\n\n    def _standardize(self, df):\n        col_map = {\n            'open': 'Open', 'high': 'High', 'low': 'Low',\n            'close': 'Close', 'volume': 'Volume',\n            'max': 'High', 'min': 'Low', 'Trading_Volume': 'Volume',\n        }\n        df = df.rename(columns=col_map)\n        for target in ['Open', 'High', 'Low', 'Close', 'Volume']:\n            if target not in df.columns:\n                for c in df.columns:\n                    if c.lower() == target.lower():\n                        df = df.rename(columns={c: target})\n                        break\n        keep = [c for c in ['Open','High','Low','Close','Volume'] if c in df.columns]\n        df = df[keep].copy()\n        if hasattr(df.index, 'tz') and df.index.tz is not None:\n            df.index = df.index.tz_localize(None)\n        for c in df.columns:\n            df[c] = pd.to_numeric(df[c], errors='coerce')\n        return df.sort_index().dropna()\n\n    @staticmethod\n    def resample(df, timeframe='1D'):\n        if timeframe == '1D' or df is None or df.empty:\n            return df\n        rule = {'1W': 'W', '1M': _MONTH_RULE}[timeframe]\n        agg = {'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'}\n        return df.resample(rule).agg(agg).dropna()\n\n    def get(self, ticker, market='TW'):\n        cp = self._cache_path(ticker, market)\n        try:\n            if self._cache_ok(cp):\n                df = pd.read_csv(cp, index_col=0, parse_dates=True)\n                self.stats['cache'] += 1\n                return self._standardize(df)\n            if market.upper() == 'TW':\n                df = self._fetch_tw(ticker)\n            else:\n                try:\n                    df = self._fetch_us(ticker)\n                except Exception:\n                    df = self._fetch_us_yf(ticker)\n            df = self._standardize(df)\n            df.to_csv(cp)\n            return df\n        except Exception:\n            self.stats['err'] += 1\n            return None\n\n# ============================================================\n# æ•¸æ“šå‰è™•ç† (è¦æ ¼æ›¸ 2.1)\n# ============================================================\n\ndef preprocess(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    æ¸…æ´—è¦å‰‡ï¼š\n    1. å‰”é™¤æˆäº¤é‡ç‚º 0 çš„éäº¤æ˜“æ—¥\n    2. å‰”é™¤ High == Low (ç„¡æ³¢å‹•) çš„æ­»é­šç›¤ K ç·š\n    \"\"\"\n    if df is None or df.empty:\n        return df\n    df = df[df['Volume'] > 0].copy()\n    df = df[df['High'] != df['Low']].copy()\n    return df\n\n# ============================================================\n# ZigZag æ¼”ç®—æ³• (è¦æ ¼æ›¸ 2.2)\n# ============================================================\n\ndef zigzag(df: pd.DataFrame, threshold: float = ZIGZAG_THRESHOLD, \n           min_bars: int = ZIGZAG_MIN_BARS) -> List[Pivot]:\n    \"\"\"\n    ZigZag æ³¢æ®µè­˜åˆ¥æ¼”ç®—æ³•\n    - åƒ…ç•¶åƒ¹æ ¼è‡ªæ¥µå€¼å›èª¿è¶…é threshold æ™‚ï¼Œç¢ºèªè©²æ¥µå€¼é»\n    - è¼¸å‡º: Pivot åºåˆ— [P0, P1, P2, ...] (P0 ç‚ºæœ€æ–°è½‰æŠ˜é»)\n    \"\"\"\n    if df is None or len(df) < min_bars * 2:\n        return []\n    \n    highs = df['High'].values\n    lows = df['Low'].values\n    dates = df.index\n    n = len(df)\n    \n    pivots = []\n    \n    # åˆå§‹åŒ–ï¼šæ‰¾ç¬¬ä¸€å€‹æ¥µå€¼\n    if highs[0] >= lows[0]:\n        last_type = 'PEAK'\n        last_idx = 0\n        last_price = highs[0]\n    else:\n        last_type = 'VALLEY'\n        last_idx = 0\n        last_price = lows[0]\n    \n    # è¿½è¹¤ç•¶å‰æ½›åœ¨æ¥µå€¼\n    potential_high_idx = 0\n    potential_high = highs[0]\n    potential_low_idx = 0\n    potential_low = lows[0]\n    \n    for i in range(1, n):\n        # æ›´æ–°æ½›åœ¨é«˜é»\n        if highs[i] > potential_high:\n            potential_high = highs[i]\n            potential_high_idx = i\n        \n        # æ›´æ–°æ½›åœ¨ä½é»\n        if lows[i] < potential_low:\n            potential_low = lows[i]\n            potential_low_idx = i\n        \n        # æª¢æŸ¥æ˜¯å¦ç¢ºèªè½‰æŠ˜\n        if last_type == 'PEAK':\n            # ç•¶å‰è¶¨å‹¢å‘ä¸‹ï¼Œå°‹æ‰¾ VALLEY\n            # å¦‚æœå¾æ½›åœ¨ä½é»åå½ˆè¶…é thresholdï¼Œç¢ºèªè©²ä½é»\n            if potential_high > 0 and (highs[i] - potential_low) / potential_low >= threshold:\n                if i - potential_low_idx >= min_bars:\n                    date_str = str(dates[potential_low_idx].date()) if hasattr(dates[potential_low_idx], 'date') else str(dates[potential_low_idx])\n                    pivots.append(Pivot(potential_low_idx, potential_low, 'VALLEY', date_str))\n                    last_type = 'VALLEY'\n                    last_idx = potential_low_idx\n                    last_price = potential_low\n                    # é‡ç½®æ½›åœ¨é«˜é»\n                    potential_high = highs[i]\n                    potential_high_idx = i\n        else:\n            # ç•¶å‰è¶¨å‹¢å‘ä¸Šï¼Œå°‹æ‰¾ PEAK\n            # å¦‚æœå¾æ½›åœ¨é«˜é»å›è½è¶…é thresholdï¼Œç¢ºèªè©²é«˜é»\n            if potential_low > 0 and (potential_high - lows[i]) / potential_high >= threshold:\n                if i - potential_high_idx >= min_bars:\n                    date_str = str(dates[potential_high_idx].date()) if hasattr(dates[potential_high_idx], 'date') else str(dates[potential_high_idx])\n                    pivots.append(Pivot(potential_high_idx, potential_high, 'PEAK', date_str))\n                    last_type = 'PEAK'\n                    last_idx = potential_high_idx\n                    last_price = potential_high\n                    # é‡ç½®æ½›åœ¨ä½é»\n                    potential_low = lows[i]\n                    potential_low_idx = i\n    \n    # é€†åºè¿”å› (P0 ç‚ºæœ€æ–°)\n    return list(reversed(pivots))\n\n# ============================================================\n# å½¢æ…‹è­˜åˆ¥ (è¦æ ¼æ›¸ 3.x)\n# ============================================================\n\nclass PatternDetector:\n    \"\"\"å½¢æ…‹è­˜åˆ¥å™¨\"\"\"\n    \n    @staticmethod\n    def detect_double_bottom(pivots: List[Pivot], df: pd.DataFrame) -> Optional[Pattern]:\n        \"\"\"\n        é›™é‡åº• (W-Bottom) - 4 é»è­˜åˆ¥\n        æ¢ä»¶ï¼š\n        1. P4 (å·¦è…³), P2 (å³è…³) ç‚º VALLEY\n        2. é›™è…³æ°´å¹³: |P4 - P2| / P4 <= 3%\n        3. P3 (é ¸ç·š) æ¯” P4 é«˜å‡ºè‡³å°‘ 8%\n        4. P4 èˆ‡ P2 é–“éš”è‡³å°‘ 15 å€‹äº¤æ˜“å–®ä½\n        \"\"\"\n        if len(pivots) < 4:\n            return None\n        \n        # å–æœ€è¿‘ 4 å€‹è½‰æŠ˜é» (P0 æœ€æ–°)\n        p0, p1, p2, p3 = pivots[0], pivots[1], pivots[2], pivots[3]\n        \n        # æª¢æŸ¥ P2, P4 éƒ½æ˜¯ VALLEY (P4=p3, P2=p1 in 0-indexed)\n        # å¯¦éš›ä¸Š 4 é»æ˜¯ P1, P2, P3, P4ï¼ŒP4 æœ€èˆŠ\n        # pivots[0]=P1(æœ€æ–°), pivots[1]=P2, pivots[2]=P3, pivots[3]=P4(æœ€èˆŠ)\n        \n        # Wåº•: P4(VALLEY) - P3(PEAK) - P2(VALLEY) - P1(PEAK/ç•¶å‰)\n        # éœ€è¦ P4 å’Œ P2 æ˜¯ VALLEYï¼ŒP3 æ˜¯ PEAK\n        \n        if p3.type != 'VALLEY' or p1.type != 'VALLEY':\n            return None\n        if p2.type != 'PEAK':\n            return None\n        \n        left_bottom = p3.price   # P4 (å·¦è…³)\n        right_bottom = p1.price  # P2 (å³è…³)\n        neckline = p2.price      # P3 (é ¸ç·šé«˜é»)\n        \n        # æ¢ä»¶ 2: é›™è…³æ°´å¹³ 3% å…§\n        if abs(left_bottom - right_bottom) / left_bottom > TOLERANCE:\n            return None\n        \n        # æ¢ä»¶ 3: é ¸ç·šé«˜åº¦ 8%+\n        avg_bottom = (left_bottom + right_bottom) / 2\n        if (neckline - avg_bottom) / avg_bottom < NECKLINE_MIN_HEIGHT:\n            return None\n        \n        # æ¢ä»¶ 4: æ™‚é–“è·¨åº¦ 15+\n        if p1.idx - p3.idx < MIN_PATTERN_BARS:\n            return None\n        \n        return Pattern(\n            type='DOUBLE_BOTTOM',\n            direction='bullish',\n            pivots=[p3, p2, p1, p0] if p0 else [p3, p2, p1],\n            neckline=neckline,\n            end_idx=p1.idx\n        )\n    \n    @staticmethod\n    def detect_double_top(pivots: List[Pivot], df: pd.DataFrame) -> Optional[Pattern]:\n        \"\"\"\n        é›™é‡é ‚ (M-Top) - 4 é»è­˜åˆ¥\n        \"\"\"\n        if len(pivots) < 4:\n            return None\n        \n        p0, p1, p2, p3 = pivots[0], pivots[1], pivots[2], pivots[3]\n        \n        # Mé ­: P4(PEAK) - P3(VALLEY) - P2(PEAK) - P1(VALLEY/ç•¶å‰)\n        if p3.type != 'PEAK' or p1.type != 'PEAK':\n            return None\n        if p2.type != 'VALLEY':\n            return None\n        \n        left_top = p3.price\n        right_top = p1.price\n        neckline = p2.price\n        \n        # é›™é ­æ°´å¹³ 3% å…§\n        if abs(left_top - right_top) / left_top > TOLERANCE:\n            return None\n        \n        # é ¸ç·šæ·±åº¦ 8%+\n        avg_top = (left_top + right_top) / 2\n        if (avg_top - neckline) / avg_top < NECKLINE_MIN_HEIGHT:\n            return None\n        \n        # æ™‚é–“è·¨åº¦ 15+\n        if p1.idx - p3.idx < MIN_PATTERN_BARS:\n            return None\n        \n        return Pattern(\n            type='DOUBLE_TOP',\n            direction='bearish',\n            pivots=[p3, p2, p1, p0] if p0 else [p3, p2, p1],\n            neckline=neckline,\n            end_idx=p1.idx\n        )\n    \n    @staticmethod\n    def detect_hs_bottom(pivots: List[Pivot], df: pd.DataFrame) -> Optional[Pattern]:\n        \"\"\"\n        é ­è‚©åº• (H&S Bottom) - 5 é»è­˜åˆ¥\n        æ¢ä»¶ï¼š\n        1. P5(å·¦è‚©åº•), P3(é ­åº•), P1(å³è‚©åº•) ç‚º VALLEY\n        2. P3 < P5 ä¸” P3 < P1 (é ­éƒ¨æœ€ä½)\n        3. |P5 - P1| / P3 < 10%\n        4. å³è‚©å½¢æˆæ™‚é–“ > å·¦è‚©æ™‚é–“ Ã— 0.3\n        5. é ¸ç·šæ–œç‡ â‰¤ 30Â°\n        \"\"\"\n        if len(pivots) < 5:\n            return None\n        \n        p0, p1, p2, p3, p4 = pivots[0], pivots[1], pivots[2], pivots[3], pivots[4]\n        \n        # æª¢æŸ¥æ¥µå€¼å±¬æ€§ï¼šP5, P3, P1 æ˜¯ VALLEY\n        # p4=P5, p2=P3(é ­), p0=P1(å¦‚æœæœ‰çš„è©±)æˆ–p1=P1\n        # å¯¦éš›: pivots[4]=å·¦è‚©, pivots[2]=é ­, pivots[0]=å³è‚© (å¦‚æœéƒ½æ˜¯VALLEY)\n        \n        # é ­è‚©åº•: VALLEY(å·¦è‚©) - PEAK - VALLEY(é ­) - PEAK - VALLEY(å³è‚©)\n        if p4.type != 'VALLEY' or p2.type != 'VALLEY' or p0.type != 'VALLEY':\n            return None\n        if p3.type != 'PEAK' or p1.type != 'PEAK':\n            return None\n        \n        left_shoulder = p4.price\n        head = p2.price\n        right_shoulder = p0.price\n        \n        # æ¢ä»¶ 2: é ­éƒ¨æœ€ä½\n        if not (head < left_shoulder and head < right_shoulder):\n            return None\n        \n        # æ¢ä»¶ 3: å°ç¨±æ€§ 10%\n        if abs(left_shoulder - right_shoulder) / head > HS_SYMMETRY_TOL:\n            return None\n        \n        # æ¢ä»¶ 4: æ™‚é–“å°ç¨±\n        left_time = p2.idx - p4.idx\n        right_time = p0.idx - p2.idx\n        if right_time < left_time * 0.3:\n            return None\n        \n        # æ¢ä»¶ 5: é ¸ç·šæ–œç‡ (é€£æ¥ P4 èˆ‡ P2 çš„é«˜é»)\n        neckline_left = p3.price   # å·¦é ¸ç·šé»\n        neckline_right = p1.price  # å³é ¸ç·šé»\n        time_diff = p1.idx - p3.idx\n        if time_diff > 0:\n            price_diff = abs(neckline_right - neckline_left)\n            avg_price = (neckline_left + neckline_right) / 2\n            slope_ratio = price_diff / avg_price / time_diff * 100\n            slope_deg = math.degrees(math.atan(slope_ratio))\n            if abs(slope_deg) > NECKLINE_MAX_SLOPE:\n                return None\n        \n        neckline = (neckline_left + neckline_right) / 2\n        \n        return Pattern(\n            type='HS_BOTTOM',\n            direction='bullish',\n            pivots=[p4, p3, p2, p1, p0],\n            neckline=neckline,\n            end_idx=p0.idx\n        )\n    \n    @staticmethod\n    def detect_hs_top(pivots: List[Pivot], df: pd.DataFrame) -> Optional[Pattern]:\n        \"\"\"\n        é ­è‚©é ‚ (H&S Top) - 5 é»è­˜åˆ¥\n        \"\"\"\n        if len(pivots) < 5:\n            return None\n        \n        p0, p1, p2, p3, p4 = pivots[0], pivots[1], pivots[2], pivots[3], pivots[4]\n        \n        # é ­è‚©é ‚: PEAK(å·¦è‚©) - VALLEY - PEAK(é ­) - VALLEY - PEAK(å³è‚©)\n        if p4.type != 'PEAK' or p2.type != 'PEAK' or p0.type != 'PEAK':\n            return None\n        if p3.type != 'VALLEY' or p1.type != 'VALLEY':\n            return None\n        \n        left_shoulder = p4.price\n        head = p2.price\n        right_shoulder = p0.price\n        \n        # é ­éƒ¨æœ€é«˜\n        if not (head > left_shoulder and head > right_shoulder):\n            return None\n        \n        # å°ç¨±æ€§ 10%\n        if abs(left_shoulder - right_shoulder) / head > HS_SYMMETRY_TOL:\n            return None\n        \n        # æ™‚é–“å°ç¨±\n        left_time = p2.idx - p4.idx\n        right_time = p0.idx - p2.idx\n        if right_time < left_time * 0.3:\n            return None\n        \n        # é ¸ç·šæ–œç‡\n        neckline_left = p3.price\n        neckline_right = p1.price\n        time_diff = p1.idx - p3.idx\n        if time_diff > 0:\n            price_diff = abs(neckline_right - neckline_left)\n            avg_price = (neckline_left + neckline_right) / 2\n            slope_ratio = price_diff / avg_price / time_diff * 100\n            slope_deg = math.degrees(math.atan(slope_ratio))\n            if abs(slope_deg) > NECKLINE_MAX_SLOPE:\n                return None\n        \n        neckline = (neckline_left + neckline_right) / 2\n        \n        return Pattern(\n            type='HS_TOP',\n            direction='bearish',\n            pivots=[p4, p3, p2, p1, p0],\n            neckline=neckline,\n            end_idx=p0.idx\n        )\n    \n    @staticmethod\n    def detect_cup_handle(df: pd.DataFrame, pivots: List[Pivot]) -> Optional[Pattern]:\n        \"\"\"\n        æ¯æŸ„å½¢æ…‹ (Cup and Handle)\n        æ¢ä»¶ï¼š\n        1. æ¯èº«: 60-150 æ ¹ K ç·šå…§çš„ U å‹çµæ§‹\n        2. æ¯åº•ä½æ–¼å€é–“ä¸­é–“ 50% æ™‚é–“å¸¶å…§\n        3. æŸ„éƒ¨åœ¨ High_Right ä¹‹å¾Œ\n        4. æŸ„éƒ¨å›èª¿ â‰¤ æ¯èº«æ·±åº¦ Ã— 0.382\n        \"\"\"\n        if df is None or len(df) < 60:\n            return None\n        \n        # æª¢æŸ¥æœ€è¿‘ 60-150 æ ¹ K ç·š\n        lookback = min(150, len(df))\n        recent = df.iloc[-lookback:]\n        \n        # æ‰¾æ¯èº«é«˜é»å’Œä½é»\n        high_left_idx = recent['High'].iloc[:lookback//3].idxmax()\n        high_right_idx = recent['High'].iloc[-lookback//3:].idxmax()\n        \n        left_idx = recent.index.get_loc(high_left_idx)\n        right_idx = recent.index.get_loc(high_right_idx)\n        \n        if right_idx - left_idx < 30:\n            return None\n        \n        cup_section = recent.iloc[left_idx:right_idx+1]\n        if len(cup_section) < 30:\n            return None\n        \n        low_idx = cup_section['Low'].idxmin()\n        low_pos = cup_section.index.get_loc(low_idx)\n        \n        # æ¯åº•å¿…é ˆåœ¨ä¸­é–“ 50%\n        section_len = len(cup_section)\n        if not (section_len * 0.25 < low_pos < section_len * 0.75):\n            return None\n        \n        high_left = recent['High'].loc[high_left_idx]\n        high_right = recent['High'].loc[high_right_idx]\n        low_min = cup_section['Low'].loc[low_idx]\n        \n        cup_depth = ((high_left + high_right) / 2) - low_min\n        \n        # æª¢æŸ¥æŸ„éƒ¨ (æ¯èº«å³å´ä¹‹å¾Œ)\n        if right_idx + 5 >= len(recent):\n            return None\n        \n        handle_section = recent.iloc[right_idx:]\n        if len(handle_section) < 3:\n            return None\n        \n        handle_low = handle_section['Low'].min()\n        handle_pullback = high_right - handle_low\n        \n        # æŸ„éƒ¨å›èª¿ â‰¤ æ¯èº« Ã— 0.382\n        if handle_pullback > cup_depth * 0.382:\n            return None\n        \n        # ç•¶å‰åƒ¹æ ¼\n        current_close = df['Close'].iloc[-1]\n        \n        # å‰µå»º Pattern\n        neckline = (high_left + high_right) / 2\n        \n        # æ§‹é€ è™›æ“¬ Pivots\n        date_low = str(low_idx.date()) if hasattr(low_idx, 'date') else str(low_idx)\n        cup_low_pivot = Pivot(len(df) - lookback + low_pos, low_min, 'VALLEY', date_low)\n        \n        return Pattern(\n            type='CUP_HANDLE',\n            direction='bullish',\n            pivots=[cup_low_pivot],\n            neckline=neckline,\n            end_idx=len(df) - 1\n        )\n    \n    @staticmethod\n    def detect_all(df: pd.DataFrame, pivots: List[Pivot]) -> List[Pattern]:\n        \"\"\"æª¢æ¸¬æ‰€æœ‰å½¢æ…‹\"\"\"\n        patterns = []\n        \n        # é›™é‡åº•\n        pat = PatternDetector.detect_double_bottom(pivots, df)\n        if pat:\n            patterns.append(pat)\n        \n        # é›™é‡é ‚\n        pat = PatternDetector.detect_double_top(pivots, df)\n        if pat:\n            patterns.append(pat)\n        \n        # é ­è‚©åº•\n        pat = PatternDetector.detect_hs_bottom(pivots, df)\n        if pat:\n            patterns.append(pat)\n        \n        # é ­è‚©é ‚\n        pat = PatternDetector.detect_hs_top(pivots, df)\n        if pat:\n            patterns.append(pat)\n        \n        # æ¯æŸ„\n        pat = PatternDetector.detect_cup_handle(df, pivots)\n        if pat:\n            patterns.append(pat)\n        \n        return patterns\n\n# ============================================================\n# é åˆ¤å‹è§¸ç™¼æ©Ÿåˆ¶ (è¦æ ¼æ›¸ 4.x)\n# ============================================================\n\nclass PredictiveTrigger:\n    \"\"\"é åˆ¤å‹è§¸ç™¼æª¢æŸ¥\"\"\"\n    \n    @staticmethod\n    def check_trigger(df: pd.DataFrame, pattern: Pattern) -> bool:\n        \"\"\"æª¢æŸ¥æ˜¯å¦è§¸ç™¼é åˆ¤è¨Šè™Ÿ\"\"\"\n        if df is None or df.empty:\n            return False\n        \n        current_close = df['Close'].iloc[-1]\n        \n        if pattern.direction == 'bullish':\n            # çœ‹å¤š: Close > Low_Right Ã— 1.02\n            right_low = PredictiveTrigger._get_right_low(pattern)\n            if right_low and current_close > right_low * (1 + TRIGGER_THRESHOLD):\n                return True\n        else:\n            # çœ‹ç©º: Close < High_Right Ã— 0.98\n            right_high = PredictiveTrigger._get_right_high(pattern)\n            if right_high and current_close < right_high * (1 - TRIGGER_THRESHOLD):\n                return True\n        \n        return False\n    \n    @staticmethod\n    def check_invalidation(df: pd.DataFrame, pattern: Pattern) -> bool:\n        \"\"\"æª¢æŸ¥å½¢æ…‹æ˜¯å¦å¤±æ•ˆ\"\"\"\n        if df is None or df.empty:\n            return False\n        \n        current_close = df['Close'].iloc[-1]\n        \n        if pattern.direction == 'bullish':\n            right_low = PredictiveTrigger._get_right_low(pattern)\n            if right_low and current_close < right_low:\n                return True\n        else:\n            right_high = PredictiveTrigger._get_right_high(pattern)\n            if right_high and current_close > right_high:\n                return True\n        \n        return False\n    \n    @staticmethod\n    def _get_right_low(pattern: Pattern) -> Optional[float]:\n        \"\"\"å–å¾—å³å´æœ€ä½é»\"\"\"\n        if pattern.type == 'DOUBLE_BOTTOM':\n            # P2 (å³è…³) æ˜¯ pivots[2] æˆ–çœ‹æœ€æ–°çš„ VALLEY\n            for p in pattern.pivots:\n                if p.type == 'VALLEY':\n                    return p.price\n        elif pattern.type == 'HS_BOTTOM':\n            # å³è‚©åº•\n            if pattern.pivots and pattern.pivots[-1].type == 'VALLEY':\n                return pattern.pivots[-1].price\n        elif pattern.type == 'CUP_HANDLE':\n            if pattern.pivots:\n                return pattern.pivots[0].price\n        return None\n    \n    @staticmethod\n    def _get_right_high(pattern: Pattern) -> Optional[float]:\n        \"\"\"å–å¾—å³å´æœ€é«˜é»\"\"\"\n        if pattern.type == 'DOUBLE_TOP':\n            for p in pattern.pivots:\n                if p.type == 'PEAK':\n                    return p.price\n        elif pattern.type == 'HS_TOP':\n            if pattern.pivots and pattern.pivots[-1].type == 'PEAK':\n                return pattern.pivots[-1].price\n        return None\n\n# ============================================================\n# è©•åˆ†ç³»çµ± (è¦æ ¼æ›¸ 5.x)\n# ============================================================\n\nclass QualityScorer:\n    \"\"\"å“è³ªè©•åˆ†å™¨\"\"\"\n    \n    @staticmethod\n    def score(df: pd.DataFrame, pattern: Pattern) -> Tuple[int, Dict]:\n        \"\"\"\n        è¨ˆç®—å“è³ªåˆ†æ•¸\n        - æˆäº¤é‡ (40%): å³å´é‡ç¸® +20, åå½ˆå‡ºé‡ +20\n        - è¶¨å‹¢ä½ç½® (30%): BBä¸‹ç·£/200MAé™„è¿‘ +30\n        - å½¢æ…‹å®Œæ•´åº¦ (30%): å°ç¨±æ€§ +15, æ°´å¹³åº¦ +15\n        \"\"\"\n        breakdown = {'volume': 0, 'trend': 0, 'morphology': 0}\n        \n        # æˆäº¤é‡è©•åˆ†\n        vol_score = QualityScorer._score_volume(df, pattern)\n        breakdown['volume'] = vol_score\n        \n        # è¶¨å‹¢ä½ç½®è©•åˆ†\n        trend_score = QualityScorer._score_trend(df, pattern)\n        breakdown['trend'] = trend_score\n        \n        # å½¢æ…‹å®Œæ•´åº¦è©•åˆ†\n        morph_score = QualityScorer._score_morphology(pattern)\n        breakdown['morphology'] = morph_score\n        \n        # åŠ æ¬Šç¸½åˆ†\n        total = (\n            vol_score * WEIGHT_VOLUME +\n            trend_score * WEIGHT_TREND +\n            morph_score * WEIGHT_MORPHOLOGY\n        )\n        \n        return int(round(total)), breakdown\n    \n    @staticmethod\n    def _score_volume(df: pd.DataFrame, pattern: Pattern) -> int:\n        \"\"\"æˆäº¤é‡è©•åˆ† (æ»¿åˆ† 100)\"\"\"\n        score = 0\n        \n        if len(df) < 40:\n            return 50  # æ•¸æ“šä¸è¶³ï¼Œçµ¦ä¸­é–“åˆ†\n        \n        # è¨ˆç®— 20 æ—¥å‡é‡\n        vol_ma20 = df['Volume'].rolling(20).mean()\n        \n        end_idx = pattern.end_idx\n        if end_idx < 20 or end_idx >= len(df):\n            return 50\n        \n        # å³å´é‡ç¸®æª¢æŸ¥\n        if pattern.type in ['DOUBLE_BOTTOM', 'HS_BOTTOM', 'CUP_HANDLE']:\n            # æ‰¾å·¦å³è…³çš„å¹³å‡æˆäº¤é‡\n            mid_idx = end_idx - 10\n            if mid_idx > 10:\n                left_vol = df['Volume'].iloc[mid_idx-10:mid_idx].mean()\n                right_vol = df['Volume'].iloc[mid_idx:end_idx].mean()\n                if right_vol < left_vol:\n                    score += 50  # å³å´é‡ç¸® +50 (æ›ç®—æˆ +20 æ¬Šé‡)\n        \n        # åå½ˆå‡ºé‡æª¢æŸ¥\n        today_vol = df['Volume'].iloc[-1]\n        avg_vol = vol_ma20.iloc[-1] if not pd.isna(vol_ma20.iloc[-1]) else df['Volume'].mean()\n        if today_vol > avg_vol:\n            score += 50  # åå½ˆå‡ºé‡ +50\n        \n        return min(100, score)\n    \n    @staticmethod\n    def _score_trend(df: pd.DataFrame, pattern: Pattern) -> int:\n        \"\"\"è¶¨å‹¢ä½ç½®è©•åˆ† (æ»¿åˆ† 100)\"\"\"\n        if len(df) < 200:\n            return 50\n        \n        current_close = df['Close'].iloc[-1]\n        \n        # è¨ˆç®— 200MA\n        ma200 = df['Close'].rolling(200).mean().iloc[-1]\n        \n        # è¨ˆç®— Bollinger Band\n        ma20 = df['Close'].rolling(20).mean().iloc[-1]\n        std20 = df['Close'].rolling(20).std().iloc[-1]\n        bb_lower = ma20 - 2 * std20\n        bb_upper = ma20 + 2 * std20\n        \n        score = 0\n        \n        if pattern.direction == 'bullish':\n            # å¤šé ­å½¢æ…‹ï¼šæ¥è¿‘ BB ä¸‹ç·£æˆ– 200MA\n            if current_close <= bb_lower * 1.02:\n                score = 100\n            elif current_close <= ma200 * 1.05:\n                score = 80\n            elif current_close <= ma20:\n                score = 50\n        else:\n            # ç©ºé ­å½¢æ…‹ï¼šæ¥è¿‘ BB ä¸Šç·£\n            if current_close >= bb_upper * 0.98:\n                score = 100\n            elif current_close >= ma200 * 0.95:\n                score = 80\n            elif current_close >= ma20:\n                score = 50\n        \n        return score\n    \n    @staticmethod\n    def _score_morphology(pattern: Pattern) -> int:\n        \"\"\"å½¢æ…‹å®Œæ•´åº¦è©•åˆ† (æ»¿åˆ† 100)\"\"\"\n        score = 0\n        \n        if not pattern.pivots or len(pattern.pivots) < 2:\n            return 50\n        \n        # å°ç¨±æ€§è©•åˆ† (æ™‚é–“å°ç¨±)\n        if pattern.type in ['DOUBLE_BOTTOM', 'DOUBLE_TOP'] and len(pattern.pivots) >= 3:\n            p_left = pattern.pivots[0]\n            p_mid = pattern.pivots[1]\n            p_right = pattern.pivots[2]\n            left_time = p_mid.idx - p_left.idx\n            right_time = p_right.idx - p_mid.idx\n            if left_time > 0:\n                time_ratio = abs(left_time - right_time) / left_time\n                if time_ratio < 0.2:\n                    score += 50  # å°ç¨±æ€§å¥½\n                elif time_ratio < 0.4:\n                    score += 25\n        \n        # æ°´å¹³åº¦è©•åˆ† (åƒ¹æ ¼æ°´å¹³)\n        if pattern.type == 'DOUBLE_BOTTOM' and len(pattern.pivots) >= 3:\n            left_price = pattern.pivots[0].price\n            right_price = pattern.pivots[2].price if len(pattern.pivots) > 2 else pattern.pivots[1].price\n            price_diff = abs(left_price - right_price) / left_price\n            if price_diff < 0.01:\n                score += 50  # éå¸¸æ°´å¹³\n            elif price_diff < 0.02:\n                score += 35\n            elif price_diff < 0.03:\n                score += 20\n        elif pattern.type == 'DOUBLE_TOP' and len(pattern.pivots) >= 3:\n            left_price = pattern.pivots[0].price\n            right_price = pattern.pivots[2].price if len(pattern.pivots) > 2 else pattern.pivots[1].price\n            price_diff = abs(left_price - right_price) / left_price\n            if price_diff < 0.01:\n                score += 50\n            elif price_diff < 0.02:\n                score += 35\n            elif price_diff < 0.03:\n                score += 20\n        else:\n            score += 30  # å…¶ä»–å½¢æ…‹çµ¦åŸºæœ¬åˆ†\n        \n        return min(100, score)\n\n# ============================================================\n# ç›®æ¨™åƒ¹è¨ˆç®— (è¦æ ¼æ›¸ 6)\n# ============================================================\n\nclass TargetCalculator:\n    \"\"\"ç›®æ¨™åƒ¹è¨ˆç®—å™¨\"\"\"\n    \n    @staticmethod\n    def calculate(df: pd.DataFrame, pattern: Pattern) -> Dict:\n        \"\"\"è¨ˆç®—åœæå’Œç›®æ¨™åƒ¹\"\"\"\n        result = {\n            'entry_zone': round(df['Close'].iloc[-1], 2),\n            'stop_loss': 0.0,\n            'target_neckline': round(pattern.neckline, 2),\n            'measured_move_target': 0.0\n        }\n        \n        if pattern.type == 'DOUBLE_BOTTOM':\n            # åœæ: å³è…³ä½é»\n            right_low = None\n            for p in pattern.pivots:\n                if p.type == 'VALLEY':\n                    right_low = p.price\n                    break\n            if right_low:\n                result['stop_loss'] = round(right_low * 0.99, 2)  # å†ä¸‹ 1%\n            \n            # ç­‰å¹…æ¸¬è·: neckline + (neckline - avg_bottom)\n            avg_bottom = sum(p.price for p in pattern.pivots if p.type == 'VALLEY') / max(1, sum(1 for p in pattern.pivots if p.type == 'VALLEY'))\n            depth = pattern.neckline - avg_bottom\n            result['measured_move_target'] = round(pattern.neckline + depth, 2)\n        \n        elif pattern.type == 'DOUBLE_TOP':\n            # åœæ: å³é ­é«˜é»\n            right_high = None\n            for p in pattern.pivots:\n                if p.type == 'PEAK':\n                    right_high = p.price\n                    break\n            if right_high:\n                result['stop_loss'] = round(right_high * 1.01, 2)\n            \n            # ç­‰å¹…æ¸¬è·\n            avg_top = sum(p.price for p in pattern.pivots if p.type == 'PEAK') / max(1, sum(1 for p in pattern.pivots if p.type == 'PEAK'))\n            depth = avg_top - pattern.neckline\n            result['measured_move_target'] = round(pattern.neckline - depth, 2)\n        \n        elif pattern.type == 'HS_BOTTOM':\n            # åœæ: é ­éƒ¨ä½é»\n            head_low = min(p.price for p in pattern.pivots if p.type == 'VALLEY')\n            result['stop_loss'] = round(head_low * 0.99, 2)\n            \n            # ç­‰å¹…æ¸¬è·\n            depth = pattern.neckline - head_low\n            result['measured_move_target'] = round(pattern.neckline + depth, 2)\n        \n        elif pattern.type == 'HS_TOP':\n            head_high = max(p.price for p in pattern.pivots if p.type == 'PEAK')\n            result['stop_loss'] = round(head_high * 1.01, 2)\n            \n            depth = head_high - pattern.neckline\n            result['measured_move_target'] = round(pattern.neckline - depth, 2)\n        \n        elif pattern.type == 'CUP_HANDLE':\n            # åœæ: æŸ„éƒ¨ä½é»\n            if pattern.pivots:\n                result['stop_loss'] = round(pattern.pivots[0].price * 0.99, 2)\n            \n            # ç­‰å¹…æ¸¬è·\n            cup_depth = pattern.neckline - pattern.pivots[0].price if pattern.pivots else 0\n            result['measured_move_target'] = round(pattern.neckline + cup_depth, 2)\n        \n        return result\n\n# ============================================================\n# å¸‚å ´æƒæå™¨\n# ============================================================\n\nclass MarketScanner:\n    def __init__(self, dm: DataManager, ctrl: ScanControl = None):\n        self.dm = dm\n        self.ctrl = ctrl or ScanControl()\n    \n    def scan(self, market: str, tickers: List[str]) -> List[PatternSignal]:\n        results = []\n        ok, fail = 0, 0\n        n = len(tickers)\n        \n        print(f'\\n{\"=\"*55}')\n        print(f'æƒæ {market} ({n} æª” x {len(TIMEFRAMES)} æ™‚æ¡†)')\n        print(f'{\"=\"*55}')\n        \n        pbar = tqdm(tickers, desc=f'{market}', unit='æª”')\n        for ticker in pbar:\n            if self.ctrl.should_stop:\n                print(f'\\nä½¿ç”¨è€…ä¸­æ­¢ (å·²å®Œæˆ {ok+fail}/{n})')\n                break\n            \n            try:\n                df_daily = self.dm.get(ticker, market)\n                if df_daily is None or len(df_daily) < 60:\n                    fail += 1\n                    continue\n                \n                # å‰è™•ç†\n                df_daily = preprocess(df_daily)\n                if df_daily is None or len(df_daily) < 60:\n                    fail += 1\n                    continue\n                \n                for tf in TIMEFRAMES:\n                    df = DataManager.resample(df_daily, tf)\n                    if df is None or len(df) < 60:\n                        continue\n                    \n                    # 1. ZigZag æ³¢æ®µè­˜åˆ¥\n                    pivots = zigzag(df)\n                    if len(pivots) < 4:\n                        continue\n                    \n                    # 2. å½¢æ…‹è­˜åˆ¥\n                    patterns = PatternDetector.detect_all(df, pivots)\n                    \n                    for pat in patterns:\n                        # 3. é åˆ¤è§¸ç™¼æª¢æŸ¥\n                        if not PredictiveTrigger.check_trigger(df, pat):\n                            continue\n                        \n                        # æª¢æŸ¥æ˜¯å¦å¤±æ•ˆ\n                        if PredictiveTrigger.check_invalidation(df, pat):\n                            continue\n                        \n                        # 4. è©•åˆ†\n                        score, breakdown = QualityScorer.score(df, pat)\n                        if score < QUALITY_THRESHOLD:\n                            continue\n                        \n                        # 5. è¨ˆç®—ç›®æ¨™åƒ¹\n                        targets = TargetCalculator.calculate(df, pat)\n                        \n                        # è¨ˆç®—ç›ˆè™§æ¯”\n                        entry = targets['entry_zone']\n                        stop = targets['stop_loss']\n                        target1 = targets['target_neckline']\n                        \n                        if pat.direction == 'bullish' and entry > stop:\n                            risk = entry - stop\n                            reward = target1 - entry\n                            rr_ratio = round(reward / risk, 2) if risk > 0 else 0\n                        elif pat.direction == 'bearish' and stop > entry:\n                            risk = stop - entry\n                            reward = entry - target1\n                            rr_ratio = round(reward / risk, 2) if risk > 0 else 0\n                        else:\n                            rr_ratio = 0\n                        \n                        # 6. çµ„è£è¼¸å‡º\n                        signal = PatternSignal(\n                            symbol=f\"{ticker}.{market}\",\n                            pattern_type=pat.type,\n                            signal_type='PREDICTIVE_LONG' if pat.direction == 'bullish' else 'PREDICTIVE_SHORT',\n                            timestamp=str(df.index[-1].date()) if hasattr(df.index[-1], 'date') else str(df.index[-1]),\n                            timeframe=tf,\n                            quality_score=score,\n                            entry_zone=targets['entry_zone'],\n                            stop_loss=targets['stop_loss'],\n                            target_neckline=targets['target_neckline'],\n                            measured_move_target=targets['measured_move_target'],\n                            risk_reward_ratio=rr_ratio,\n                            pattern_details={\n                                'pivots': [(p.date, p.price, p.type) for p in pat.pivots],\n                                'neckline': pat.neckline,\n                            },\n                            score_breakdown=breakdown\n                        )\n                        results.append(signal)\n                \n                ok += 1\n            except Exception as e:\n                fail += 1\n            \n            pbar.set_postfix({\n                'OK': ok, 'Fail': fail,\n                'è¨Šè™Ÿ': len(results),\n                'å¿«å–': self.dm.stats['cache']\n            })\n        \n        s = self.dm.stats\n        yf_info = f' yf={s[\"yf_fallback\"]}' if s['yf_fallback'] else ''\n        print(f'å®Œæˆ {ok}/{ok+fail} | API: US={s[\"api_us\"]} TW={s[\"api_tw\"]}{yf_info} | å¿«å–={s[\"cache\"]} | éŒ¯èª¤={s[\"err\"]}')\n        print(f'æ‰¾åˆ° {len(results)} å€‹é åˆ¤è¨Šè™Ÿ (å“è³ª>={QUALITY_THRESHOLD})')\n        return results\n    \n    @staticmethod\n    def to_df(results: List[PatternSignal]) -> pd.DataFrame:\n        if not results:\n            return pd.DataFrame(columns=['ä»£è™Ÿ','å¸‚å ´','é€±æœŸ','å½¢æ…‹','è¨Šè™Ÿ','åˆ†æ•¸','é€²å ´','åœæ','ç›®æ¨™1','ç›®æ¨™2','R:R'])\n        \n        rows = []\n        for r in results:\n            symbol_parts = r.symbol.split('.')\n            ticker = symbol_parts[0]\n            market = symbol_parts[1] if len(symbol_parts) > 1 else ''\n            \n            pattern_names = {\n                'DOUBLE_BOTTOM': 'Wåº•',\n                'DOUBLE_TOP': 'Mé ­',\n                'HS_BOTTOM': 'é ­è‚©åº•',\n                'HS_TOP': 'é ­è‚©é ‚',\n                'CUP_HANDLE': 'æ¯æŸ„'\n            }\n            \n            rows.append({\n                'ä»£è™Ÿ': ticker,\n                'å¸‚å ´': market,\n                'é€±æœŸ': TF_LABELS.get(r.timeframe, r.timeframe),\n                'å½¢æ…‹': pattern_names.get(r.pattern_type, r.pattern_type),\n                'è¨Šè™Ÿ': 'åšå¤š' if 'LONG' in r.signal_type else 'åšç©º',\n                'åˆ†æ•¸': r.quality_score,\n                'é€²å ´': r.entry_zone,\n                'åœæ': r.stop_loss,\n                'ç›®æ¨™1': r.target_neckline,\n                'ç›®æ¨™2': r.measured_move_target,\n                'R:R': f\"1:{r.risk_reward_ratio}\"\n            })\n        \n        return pd.DataFrame(rows).sort_values('åˆ†æ•¸', ascending=False).reset_index(drop=True)\n\n# ============================================================\n# ç¹ªåœ–\n# ============================================================\n\ndef plot_stock(dm: DataManager, ticker: str, market: str, signal: PatternSignal = None):\n    \"\"\"ç¹ªè£½ K ç·šåœ–å’Œå½¢æ…‹æ¨™è¨˜\"\"\"\n    df = dm.get(ticker, market)\n    if df is None:\n        print(f'ç„¡æ³•å–å¾— {ticker}')\n        return\n    \n    df = preprocess(df)\n    \n    timeframe = '1D'\n    if signal:\n        timeframe = signal.timeframe\n    df = DataManager.resample(df, timeframe)\n    tf_label = TF_LABELS.get(timeframe, timeframe)\n    \n    fig = make_subplots(rows=2, cols=1, shared_xaxes=True,\n                        vertical_spacing=0.03, row_heights=[0.7, 0.3])\n    \n    # K ç·š\n    fig.add_trace(go.Candlestick(\n        x=df.index, open=df['Open'], high=df['High'],\n        low=df['Low'], close=df['Close'], name='Kç·š',\n        increasing_line_color='red', decreasing_line_color='green'\n    ), row=1, col=1)\n    \n    # æˆäº¤é‡\n    colors = ['red' if c >= o else 'green' for c, o in zip(df['Close'], df['Open'])]\n    fig.add_trace(go.Bar(\n        x=df.index, y=df['Volume'], marker_color=colors,\n        name='æˆäº¤é‡', opacity=0.6\n    ), row=2, col=1)\n    \n    # æ¨™è¨˜é—œéµåƒ¹ä½\n    if signal:\n        # é€²å ´åƒ¹\n        fig.add_hline(y=signal.entry_zone, line_dash=\"solid\", line_color=\"blue\",\n                      annotation_text=f\"é€²å ´ {signal.entry_zone}\", row=1, col=1)\n        # åœæ\n        fig.add_hline(y=signal.stop_loss, line_dash=\"dash\", line_color=\"red\",\n                      annotation_text=f\"åœæ {signal.stop_loss}\", row=1, col=1)\n        # ç›®æ¨™1\n        fig.add_hline(y=signal.target_neckline, line_dash=\"dot\", line_color=\"green\",\n                      annotation_text=f\"ç›®æ¨™1 {signal.target_neckline}\", row=1, col=1)\n        # ç›®æ¨™2\n        fig.add_hline(y=signal.measured_move_target, line_dash=\"dot\", line_color=\"darkgreen\",\n                      annotation_text=f\"ç›®æ¨™2 {signal.measured_move_target}\", row=1, col=1)\n        \n        # å½¢æ…‹æ¨™è¨»\n        pattern_names = {\n            'DOUBLE_BOTTOM': 'Wåº•', 'DOUBLE_TOP': 'Mé ­',\n            'HS_BOTTOM': 'é ­è‚©åº•', 'HS_TOP': 'é ­è‚©é ‚', 'CUP_HANDLE': 'æ¯æŸ„'\n        }\n        clr = 'green' if 'LONG' in signal.signal_type else 'red'\n        fig.add_annotation(\n            x=df.index[-1], y=df['High'].max(),\n            text=f\"<b>{pattern_names.get(signal.pattern_type, signal.pattern_type)}</b><br>\"\n                 f\"å“è³ª: {signal.quality_score} | R:R 1:{signal.risk_reward_ratio}\",\n            showarrow=True, font=dict(color=clr, size=14),\n            bgcolor='white', bordercolor=clr, borderwidth=2\n        )\n    \n    fig.update_layout(\n        title=f'{ticker} ({market}) â€” {tf_label}',\n        xaxis_rangeslider_visible=False,\n        height=550, showlegend=False, template='plotly_white'\n    )\n    \n    if _IN_COLAB:\n        fig.show(renderer='colab')\n    else:\n        try:\n            fig.show()\n        except Exception:\n            display(HTML(fig.to_html(include_plotlyjs='cdn', full_html=False)))\n\n# ============================================================\n# è¼‰å…¥å®Œæˆè¨Šæ¯\n# ============================================================\n\nprint(f'æ™ºæ…§å‹ K ç·šå½¢æ…‹è¾¨è­˜å¼•æ“è¼‰å…¥å®Œæˆ')\nprint(f'   ç³»çµ±é¡å‹: é åˆ¤å‹ (Predictive)')\nprint(f'   ZigZag åƒæ•¸: å›èª¿é–€æª»={ZIGZAG_THRESHOLD*100}%, æœ€å°è·¨åº¦={ZIGZAG_MIN_BARS}æ ¹')\nprint(f'   å“è³ªé–€æª»: {QUALITY_THRESHOLD}åˆ†')\nprint(f'   æ”¯æ´å½¢æ…‹: Wåº•, Mé ­, é ­è‚©åº•, é ­è‚©é ‚, æ¯æŸ„')\nprint(f'   æ™‚æ¡†: {\", \".join(TF_LABELS[t] for t in TIMEFRAMES)}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ğŸš€ Step 4: å•Ÿå‹•å„€è¡¨æ¿\n\n# ---------- å…¨åŸŸè®Šæ•¸ ----------\n_dm = None\n_scanner = None\n_results = []\n\n# ---------- çµæœå„²å­˜ç›®éŒ„ ----------\nRESULTS_DIR = Path('./results')\nRESULTS_DIR.mkdir(parents=True, exist_ok=True)\n\n# ---------- çµæœå„²å­˜å‡½æ•¸ ----------\ndef save_scan_results(results: List[PatternSignal], market: str, mode: str) -> Dict[str, str]:\n    \"\"\"\n    å„²å­˜æƒæçµæœåˆ°æª”æ¡ˆ\n\n    æª”æ¡ˆæ ¼å¼:\n    - CSV: results/scan_{market}_{date}_{time}.csv (æ–¹ä¾¿ Excel é–‹å•Ÿ)\n    - JSON: results/scan_{market}_{date}_{time}.json (å®Œæ•´è³‡æ–™ï¼Œå«è©•åˆ†æ˜ç´°)\n\n    Args:\n        results: æƒæçµæœåˆ—è¡¨\n        market: å¸‚å ´ä»£ç¢¼ (US/TW/ALL)\n        mode: æƒææ¨¡å¼ (quick/full)\n\n    Returns:\n        {'csv': csvè·¯å¾‘, 'json': jsonè·¯å¾‘}\n    \"\"\"\n    if not results:\n        return {}\n\n    # ç”¢ç”Ÿæª”å (æ—¥æœŸ_å¸‚å ´_æ¨¡å¼)\n    date_str = datetime.now().strftime('%Y-%m-%d')\n    time_str = datetime.now().strftime('%H%M')\n    base_name = f\"scan_{market}_{date_str}_{time_str}\"\n\n    csv_path = RESULTS_DIR / f\"{base_name}.csv\"\n    json_path = RESULTS_DIR / f\"{base_name}.json\"\n\n    # 1. å„²å­˜ CSV (ç°¡æ½”ç‰ˆï¼Œæ–¹ä¾¿æŸ¥çœ‹)\n    df = MarketScanner.to_df(results)\n    df.insert(0, 'æƒææ™‚é–“', datetime.now().strftime('%Y-%m-%d %H:%M'))\n    df.to_csv(csv_path, index=False, encoding='utf-8-sig')  # utf-8-sig è®“ Excel æ­£ç¢ºé¡¯ç¤ºä¸­æ–‡\n\n    # 2. å„²å­˜ JSON (å®Œæ•´ç‰ˆï¼Œå«æ‰€æœ‰ç´°ç¯€)\n    json_data = {\n        'scan_info': {\n            'timestamp': datetime.now().isoformat(),\n            'market': market,\n            'mode': mode,\n            'quality_threshold': QUALITY_THRESHOLD,\n            'total_signals': len(results),\n        },\n        'signals': []\n    }\n\n    for r in results:\n        json_data['signals'].append({\n            'symbol': r.symbol,\n            'pattern_type': r.pattern_type,\n            'signal_type': r.signal_type,\n            'timestamp': r.timestamp,\n            'timeframe': r.timeframe,\n            'quality_score': r.quality_score,\n            'entry_zone': r.entry_zone,\n            'stop_loss': r.stop_loss,\n            'target_neckline': r.target_neckline,\n            'measured_move_target': r.measured_move_target,\n            'risk_reward_ratio': r.risk_reward_ratio,\n            'score_breakdown': r.score_breakdown,\n            'pattern_details': r.pattern_details,\n        })\n\n    with open(json_path, 'w', encoding='utf-8') as f:\n        json.dump(json_data, f, ensure_ascii=False, indent=2)\n\n    return {'csv': str(csv_path), 'json': str(json_path)}\n\n\ndef list_saved_results() -> pd.DataFrame:\n    \"\"\"åˆ—å‡ºæ‰€æœ‰å·²å„²å­˜çš„æƒæçµæœ\"\"\"\n    files = list(RESULTS_DIR.glob('scan_*.csv'))\n    if not files:\n        return pd.DataFrame(columns=['æª”æ¡ˆ', 'æ—¥æœŸ', 'å¸‚å ´', 'å¤§å°'])\n\n    rows = []\n    for f in sorted(files, reverse=True):\n        # è§£ææª”å: scan_{market}_{date}_{time}.csv\n        parts = f.stem.split('_')\n        market = parts[1] if len(parts) > 1 else '?'\n        date = parts[2] if len(parts) > 2 else '?'\n        time_part = parts[3] if len(parts) > 3 else ''\n\n        rows.append({\n            'æª”æ¡ˆ': f.name,\n            'æ—¥æœŸ': f\"{date} {time_part[:2]}:{time_part[2:]}\" if time_part else date,\n            'å¸‚å ´': market,\n            'å¤§å°': f\"{f.stat().st_size / 1024:.1f} KB\"\n        })\n\n    return pd.DataFrame(rows)\n\n# ---------- UI å…ƒä»¶ ----------\nw_fm = widgets.Text(\n    value='',\n    placeholder='FinMind Token (å°è‚¡å¿…å¡«)',\n    description='FinMind:',\n    layout=widgets.Layout(width='520px'))\n\nw_tg = widgets.Text(\n    value='',\n    placeholder='Tiingo API Key (ç¾è‚¡ä¸»è¦) â€” å¤±æ•—è‡ªå‹•åˆ‡ yfinance',\n    description='Tiingo:',\n    layout=widgets.Layout(width='520px'))\n\nw_mode = widgets.Dropdown(\n    options=[\n        ('å¿«é€Ÿæƒæ (ç²¾é¸ ~120 æª”)', 'quick'),\n        ('å…¨å¸‚å ´æƒæ (å…¨ä¸Šå¸‚å…¬å¸)', 'full'),\n    ],\n    value='quick',\n    description='æ¨¡å¼:')\n\nw_market = widgets.Dropdown(\n    options=[\n        ('ç¾è‚¡ (US)', 'US'),\n        ('å°è‚¡ (TW)', 'TW'),\n        ('å…¨éƒ¨ (US + TW)', 'ALL')\n    ],\n    value='TW',\n    description='å¸‚å ´:')\n\nw_auto_save = widgets.Checkbox(\n    value=True,\n    description='è‡ªå‹•å„²å­˜çµæœ',\n    indent=False)\n\nw_scan = widgets.Button(\n    description='é–‹å§‹æƒæ',\n    button_style='success',\n    layout=widgets.Layout(width='140px', height='38px'))\n\nw_stop = widgets.Button(\n    description='åœæ­¢æƒæ',\n    button_style='danger',\n    disabled=True,\n    layout=widgets.Layout(width='120px', height='38px'))\n\nw_list_files = widgets.Button(\n    description='æŸ¥çœ‹æ­·å²',\n    button_style='info',\n    layout=widgets.Layout(width='100px', height='38px'))\n\nw_out = widgets.Output(\n    layout=widgets.Layout(border='1px solid #ccc', min_height='120px'))\n\nw_sel = widgets.Dropdown(\n    options=[],\n    description='æŸ¥çœ‹åœ–è¡¨:',\n    layout=widgets.Layout(width='520px'))\n\nw_chart = widgets.Output()\n\n\n# ---------- çµæœè¡¨æ ¼ HTML æ¸²æŸ“ ----------\ndef _render_results_table(rdf):\n    \"\"\"å°‡ DataFrame è½‰ç‚ºå¯æ²å‹•çš„ HTML è¡¨æ ¼\"\"\"\n    html_table = rdf.to_html(index=True, escape=False, classes='scan-results')\n    return HTML(f'''\n<style>\n  .scroll-table {{\n    max-height: 500px;\n    overflow-y: auto;\n    border: 1px solid #ddd;\n    border-radius: 6px;\n    margin: 8px 0;\n  }}\n  .scan-results {{\n    width: 100%;\n    border-collapse: collapse;\n    font-size: 13px;\n  }}\n  .scan-results th {{\n    position: sticky;\n    top: 0;\n    background: #2E86AB;\n    color: white;\n    padding: 8px 12px;\n    text-align: left;\n    z-index: 1;\n  }}\n  .scan-results td {{\n    padding: 6px 12px;\n    border-bottom: 1px solid #eee;\n  }}\n  .scan-results tr:hover {{\n    background: #f0f7ff;\n  }}\n</style>\n<div class=\"scroll-table\">\n  {html_table}\n</div>\n''')\n\n\n# ---------- æƒæäº‹ä»¶ ----------\ndef _on_scan(b):\n    global _dm, _scanner, _results\n\n    w_scan.disabled = True\n    w_stop.disabled = False\n    scan_ctrl.reset()\n\n    with w_out:\n        clear_output()\n\n        tg_key   = w_tg.value.strip()\n        fm_token = w_fm.value.strip()\n        mode     = w_mode.value\n        market   = w_market.value\n        auto_save = w_auto_save.value\n\n        # API Key æª¢æŸ¥\n        if not tg_key and market in ('US', 'ALL'):\n            print('æœªå¡« Tiingo API Keyï¼Œç¾è‚¡å°‡ä½¿ç”¨ yfinance å‚™æ´')\n\n        if not fm_token and market in ('TW', 'ALL'):\n            print('æœªå¡« FinMind Tokenï¼Œå°è‚¡å¯èƒ½å—é€Ÿç‡é™åˆ¶')\n\n        # å»ºç«‹ç‰©ä»¶\n        _dm = DataManager(fm_token, tg_key)\n        _scanner = MarketScanner(_dm, scan_ctrl)\n        _results = []\n\n        try:\n            # å–å¾— Ticker æ¸…å–®\n            print('å–å¾—æƒææ¸…å–®...')\n            if mode == 'quick':\n                tickers_us = QUICK_LIST['US'] if market in ('US','ALL') else []\n                tickers_tw = QUICK_LIST['TW'] if market in ('TW','ALL') else []\n            else:\n                tickers_us = (TickerRegistry.fetch_us(tg_key)\n                              if market in ('US','ALL') else [])\n                tickers_tw = (TickerRegistry.fetch_tw(fm_token)\n                              if market in ('TW','ALL') else [])\n\n            n_us, n_tw = len(tickers_us), len(tickers_tw)\n            total = n_us + n_tw\n            print(f'   ç¾è‚¡: {n_us} æª” | å°è‚¡: {n_tw} æª” | åˆè¨ˆ: {total} æª”')\n            print(f'   æ™‚æ¡†: {\", \".join(TF_LABELS[t] for t in TIMEFRAMES)}')\n            print(f'   ç³»çµ±: é åˆ¤å‹ (Predictive) | å“è³ªé–€æª»: {QUALITY_THRESHOLD}åˆ†')\n            print()\n\n            # åŸ·è¡Œæƒæ\n            if tickers_us:\n                _results.extend(_scanner.scan('US', tickers_us))\n            if tickers_tw and not scan_ctrl.should_stop:\n                _results.extend(_scanner.scan('TW', tickers_tw))\n\n            # é¡¯ç¤ºçµæœ\n            print()\n            if _results:\n                rdf = MarketScanner.to_df(_results)\n                print('=' * 55)\n                print(f'çµæœ: {len(_results)} å€‹é åˆ¤è¨Šè™Ÿ (å“è³ª>={QUALITY_THRESHOLD})')\n                print('=' * 55)\n                display(_render_results_table(rdf))\n\n                # è‡ªå‹•å„²å­˜çµæœ\n                if auto_save:\n                    saved = save_scan_results(_results, market, mode)\n                    if saved:\n                        print(f'\\nğŸ’¾ çµæœå·²å„²å­˜:')\n                        print(f'   CSV:  {saved[\"csv\"]}')\n                        print(f'   JSON: {saved[\"json\"]}')\n\n                # ä¸‹æ‹‰é¸å–®\n                pattern_names = {\n                    'DOUBLE_BOTTOM': 'Wåº•', 'DOUBLE_TOP': 'Mé ­',\n                    'HS_BOTTOM': 'é ­è‚©åº•', 'HS_TOP': 'é ­è‚©é ‚', 'CUP_HANDLE': 'æ¯æŸ„'\n                }\n                w_sel.options = [\n                    (f\"{r.symbol.split('.')[0]} | {TF_LABELS.get(r.timeframe, r.timeframe)} | \"\n                     f\"{pattern_names.get(r.pattern_type, r.pattern_type)} | \"\n                     f\"{r.quality_score}åˆ† | R:R 1:{r.risk_reward_ratio}\", i)\n                    for i, r in enumerate(_results)\n                ]\n            else:\n                print('æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„é åˆ¤è¨Šè™Ÿ')\n                if scan_ctrl.should_stop:\n                    print('   (æƒæå·²ä¸­æ­¢ï¼Œåƒ…é¡¯ç¤ºéƒ¨åˆ†çµæœ)')\n                else:\n                    print('   å¯èƒ½åŸå› :')\n                    print('   - ç›®å‰å¸‚å ´æ²’æœ‰å½¢æ…‹æ­£åœ¨å½¢æˆä¸­')\n                    print('   - å“è³ªé–€æª» 65 åˆ†éæ¿¾æ‰äº†ä½å“è³ªè¨Šè™Ÿ')\n                    print('   - é åˆ¤è§¸ç™¼æ¢ä»¶ (åå½ˆ/å›è½ 2%) å°šæœªé”æˆ')\n\n            # çµ±è¨ˆæ‘˜è¦\n            s = _dm.stats\n            yf_info = f' yfå‚™æ´={s[\"yf_fallback\"]}' if s['yf_fallback'] else ''\n            print(f'\\nçµ±è¨ˆ: API US={s[\"api_us\"]} TW={s[\"api_tw\"]}{yf_info} | '\n                  f'å¿«å–={s[\"cache\"]} | éŒ¯èª¤={s[\"err\"]}')\n\n        except Exception as e:\n            print(f'éŒ¯èª¤: {e}')\n            import traceback\n            traceback.print_exc()\n\n    w_scan.disabled = False\n    w_stop.disabled = True\n\n\ndef _on_stop(b):\n    scan_ctrl.stop()\n    w_stop.disabled = True\n    print('æ­£åœ¨åœæ­¢ï¼Œç­‰å¾…ç•¶å‰è«‹æ±‚å®Œæˆ...')\n\n\ndef _on_list_files(b):\n    \"\"\"é¡¯ç¤ºæ­·å²æƒæçµæœ\"\"\"\n    with w_out:\n        clear_output()\n        print('ğŸ“ æ­·å²æƒæçµæœ (results/ ç›®éŒ„)')\n        print('=' * 55)\n        df = list_saved_results()\n        if df.empty:\n            print('å°šç„¡å„²å­˜çš„æƒæçµæœ')\n        else:\n            display(df)\n            print(f'\\nå…± {len(df)} å€‹æª”æ¡ˆ')\n            print('æç¤º: å¯ç›´æ¥ä¸‹è¼‰ CSV æª”æ¡ˆç”¨ Excel é–‹å•Ÿ')\n\n\ndef _on_select(change):\n    if change['new'] is None or not _results:\n        return\n    r = _results[change['new']]\n    ticker = r.symbol.split('.')[0]\n    market = r.symbol.split('.')[1] if '.' in r.symbol else 'TW'\n    with w_chart:\n        clear_output()\n        plot_stock(_dm, ticker, market, r)\n\n\nw_scan.on_click(_on_scan)\nw_stop.on_click(_on_stop)\nw_list_files.on_click(_on_list_files)\nw_sel.observe(_on_select, names='value')\n\n\n# ---------- é¡¯ç¤º Dashboard ----------\ndisplay(HTML(\"\"\"\n<div style='padding:12px; background:linear-gradient(135deg,#f0f7ff,#e8f4f8);\n            border-radius:10px; margin-bottom:12px;'>\n  <h2 style='color:#2E86AB; margin:0;'>æ™ºæ…§å‹ K ç·šå½¢æ…‹è¾¨è­˜ç³»çµ±</h2>\n  <p style='color:#555; margin:5px 0 0 0; font-size:13px;'>\n    <b>é åˆ¤å‹ç³»çµ±</b> â€” åœ¨å½¢æ…‹å®Œæˆå‰æå‰è­˜åˆ¥æ½›åœ¨æ©Ÿæœƒ\n  </p>\n  <p style='color:#888; margin:3px 0 0 0; font-size:11px;'>\n    ZigZag 3% å›èª¿ | å“è³ªé–€æª» 65 åˆ† | æ”¯æ´: Wåº•, Mé ­, é ­è‚©åº•, é ­è‚©é ‚, æ¯æŸ„\n  </p>\n  <p style='color:#888; margin:3px 0 0 0; font-size:11px;'>\n    è©•åˆ†: æˆäº¤é‡ 40% + è¶¨å‹¢ä½ç½® 30% + å½¢æ…‹å®Œæ•´åº¦ 30%\n  </p>\n</div>\n\"\"\"))\n\ndisplay(widgets.VBox([\n    widgets.HTML('<b>API è¨­å®š</b>'),\n    w_fm, w_tg,\n    widgets.HTML('<b>æƒæè¨­å®š</b>'),\n    widgets.HBox([w_mode, w_market, w_auto_save]),\n    widgets.HBox([w_scan, w_stop, w_list_files]),\n], layout=widgets.Layout(\n    padding='10px', border='1px solid #ddd',\n    margin='0 0 10px 0', border_radius='8px')))\n\ndisplay(widgets.VBox([\n    widgets.HTML('<b>æƒæçµæœ</b>'),\n    w_out,\n    w_sel,\n    w_chart\n], layout=widgets.Layout(\n    padding='10px', border='1px solid #ddd', border_radius='8px')))\n\nprint('å¡«å…¥ API Key -> é¸æ“‡æ¨¡å¼/å¸‚å ´ -> é»æ“Šã€Œé–‹å§‹æƒæã€')\nprint()\nprint('è¼¸å‡ºæ¬„ä½èªªæ˜:')\nprint('  - é€²å ´: å»ºè­°é€²å ´åƒ¹ (ç•¶å‰åƒ¹)')\nprint('  - åœæ: å½¢æ…‹å¤±æ•ˆåƒ¹ (å³è…³/å³è‚©ä½é»)')\nprint('  - ç›®æ¨™1: é ¸ç·šåƒ¹æ ¼')\nprint('  - ç›®æ¨™2: ç­‰å¹…æ¸¬è·ç›®æ¨™')\nprint('  - R:R: é¢¨éšªå ±é…¬æ¯” (ç›®æ¨™1)')\nprint()\nprint('ğŸ’¾ çµæœå„²å­˜: å‹¾é¸ã€Œè‡ªå‹•å„²å­˜çµæœã€å¾Œï¼Œæƒæå®Œæˆæœƒè‡ªå‹•å­˜æª”è‡³ results/ ç›®éŒ„')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}